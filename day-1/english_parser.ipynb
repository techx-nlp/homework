{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Parser\n",
    "\n",
    "\"BuT dAvId, ThAt's JuSt A mOnOiDaL-eNdOfUnCtOr-DeRiVeD cOnTeXt-CoErCiNg LaMbDa CoMbInAtOr In SiMpLeR tErMs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import enum\n",
    "\n",
    "from xnlp.parser import (\n",
    "    Parser,\n",
    "    runParser,\n",
    "    satisfy,\n",
    "    optional,\n",
    "    zero_or_more,\n",
    "    one_or_more,\n",
    "    expect_end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to explore how to write parsing rules as described in class. The grammar you are going to design is a simplified version of English; words in such language consist of only 6 types:\n",
    "\n",
    "- `ADJ`: Adjectives (e.g. `beautiful`, `big`)\n",
    "- `ADV`: Adverbs (e.g. `gracefully`, `quickly`)\n",
    "- `NOUN`: Noun (e.g. `penguin`, `penguin`, `penguin`)\n",
    "- `PUNCT`: Punctuation (e.g. `,`, `;`, `.`)\n",
    "- `VERB`: Verb (e.g. `run`, `eat`, `slap`)\n",
    "- `CCONJ`: Coordinating Conjunctions (e.g. `but`, `and`, `yet`)\n",
    "\n",
    "For a more in-depth explanation on the above part-of-speech tags, visit [Universal POS Tags](https://universaldependencies.org/u/pos/all.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(enum.Enum):\n",
    "    \"\"\"\n",
    "    Some simple tokens. Very inconclusive, but simple.\n",
    "    \"\"\"\n",
    "\n",
    "    ADJ = 'Adjective'\n",
    "    ADV = 'Adverb'\n",
    "    NOUN = 'Noun'\n",
    "    PUNCT = 'Punctuation'\n",
    "    VERB = 'Verb'\n",
    "    CCONJ = 'Coordinating Conjunction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse each sentence, we will be using monadic parser combinators to make life easier. Here is some setup code. Feel free to skip if you are not interested.\n",
    "\n",
    "Note that the parse result will be linearized into a list for simplicity's sake. This assignment focuses more on seeing if your parser can identify grammatically correct sentences from those with grammatical errors than building the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some set-up\n",
    "\n",
    "def log_func(code):\n",
    "    return lambda x: print(f'\\033[{code}m{x}\\033[0m')\n",
    "\n",
    "\n",
    "wrapped_satisfy = lambda p: satisfy(p).fmap(lambda t: t[0])\n",
    "word = lambda w: wrapped_satisfy(lambda x: x[0] == w)\n",
    "tok = lambda t: wrapped_satisfy(lambda x: x[1] == t)\n",
    "end = expect_end('Expecting end of input')\n",
    "\n",
    "good = log_func('32')\n",
    "bad = log_func('91')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokens in a sentence is already tokenized for you. Tokens are structured as tuples:\n",
    "\n",
    "```python\n",
    "('word', T.NOUN)\n",
    "```\n",
    "\n",
    "__Tip__: for the most part, you only need to check for the token's type when constructing the parser; the only place where the string content is necessary is when an `Token.PUNCT` is encountered.\n",
    "\n",
    "Test sentences are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE = [\n",
    "    ('Elephant', T.NOUN),\n",
    "    ('eat', T.VERB),\n",
    "    ('banana', T.NOUN),\n",
    "    ('.', T.PUNCT)\n",
    "]\n",
    "\n",
    "SENTS = [\n",
    "    SIMPLE,\n",
    "    [\n",
    "        ('Big', T.ADJ),\n",
    "        ('elephant', T.NOUN),\n",
    "        ('quickly', T.ADV),\n",
    "        ('eat', T.VERB),\n",
    "        ('big', T.ADJ),\n",
    "        ('banana', T.NOUN),\n",
    "        ('.', T.PUNCT)\n",
    "    ], [\n",
    "        ('Quick', T.ADJ),\n",
    "        ('brown', T.ADJ),\n",
    "        ('fox', T.NOUN),\n",
    "        ('gracefully', T.ADV),\n",
    "        ('stabbed', T.VERB),\n",
    "        ('lazy', T.ADJ),\n",
    "        ('dog', T.NOUN),\n",
    "        ('.', T.PUNCT)\n",
    "    ], [\n",
    "        ('You', T.NOUN),\n",
    "        ('build', T.VERB),\n",
    "        ('houses', T.NOUN),\n",
    "        ('?', T.PUNCT)\n",
    "    ], [\n",
    "        ('You', T.NOUN),\n",
    "        ('build', T.VERB),\n",
    "        ('houses', T.NOUN),\n",
    "        ('!', T.PUNCT),\n",
    "    ], [\n",
    "        ('Thomas', T.NOUN),\n",
    "        ('assign', T.VERB),\n",
    "        ('homework', T.NOUN),\n",
    "        (',', T.PUNCT),\n",
    "        ('and', T.CCONJ),\n",
    "        ('George', T.NOUN),\n",
    "        ('burn', T.VERB),\n",
    "        ('homework', T.NOUN),\n",
    "        ('!', T.PUNCT)\n",
    "    ], [\n",
    "        ('Small', T.ADJ),\n",
    "        ('mouse', T.NOUN),\n",
    "        ('eat', T.VERB),\n",
    "        ('cheese', T.NOUN),\n",
    "        (',', T.PUNCT),\n",
    "        ('but', T.CCONJ),\n",
    "        ('large', T.ADJ),\n",
    "        ('cat', T.NOUN),\n",
    "        ('eat', T.VERB),\n",
    "        ('lettuce', T.NOUN),\n",
    "        ('.', T.PUNCT)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the parser is rather simple; you just need to organize everything into Backus-Naur Form like we discussed during class. To illustrate, here is how you parse a simple noun-verb-noun statement (`+` is the concatenating separator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOUN_V_NOUN = tok(T.NOUN) + tok(T.VERB) + tok(T.NOUN) + word('.') + end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try parsing the simple \"Elephant eat banana.\" sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['Elephant', 'eat', 'banana', '.']\n"
     ]
    }
   ],
   "source": [
    "print('Result:', runParser(NOUN_V_NOUN, SIMPLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that easy, yay!\n",
    "\n",
    "You might realize the similarity between our combinators and the BNF syntax; indeed, they captures the same concept. Here are some other tools:\n",
    "\n",
    "- `optional`: optionally matches a parser (e.g. `optional(tok(T.NOUN))` matches a `Noun` and returns `[<NOUN>]` if possible, otherwise returns `[]`)\n",
    "- `zero_or_more`: matches a parser as much times as possible, including empty match (e.g. `zero_or_more(tok(T.NOUN))` matches numerous `Noun` and return `[<NOUN> * n]`, where `n` can be `0`)\n",
    "- `one_or_more`: matches a parser as much times as possible, but at least once\n",
    "- `end`: matches the end of an input\n",
    "- `+`: concatenates two parsers; they must match the input string in the given order\n",
    "- `|`: joins two parsers; the new parser will success if either of the two "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our English grammar:\n",
    "\n",
    "- Simple sentences: `NOUN` + `VERB` + `NOUN` + `<END_OF_SENTENCE>`\n",
    "- Each `NOUN` can be prefixed with any amount of adjectives (e.g. 'big red fox')\n",
    "- Each `VERB` can be prefixed with one or zero `ADV` (e.g. 'quickly eat')\n",
    "- Each sentence must end in (`<END_OF_SENTENCE>` token) either '!', '?' or '.'.\n",
    "- Coordinating conjunctions ('and', 'or', 'for', 'yet', 'but', etc) joins two simple sentences together, separated by a comma ',' (e.g. 'Small mouse eat cheese, but large cat eat  lettuce.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your homework here\n",
    "\n",
    "# build a parser with the given combinators\n",
    "# according to the rules listed above\n",
    "ENGLISH_PARSER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mBuild the parser  first!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "if ENGLISH_PARSER is None:\n",
    "    bad('Build the parser first!')\n",
    "else:\n",
    "    for sent in SENTS:\n",
    "        runParser(ENGLISH_PARSER, sent)\n",
    "\n",
    "    good('Validation Tests Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
